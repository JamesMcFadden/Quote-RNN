{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quotes_RNN_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Pn0FG81KBZeP",
        "tRTEWa1_EsQJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn0FG81KBZeP"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT-JIlC0yrRb",
        "outputId": "3dd6d20b-bdec-42a5-803b-9395e1497b14"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auKEQQwsy6xX"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import resample\n",
        "\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-2bXLjgzCND",
        "outputId": "49b50330-14a6-45b6-fc79-bbf3068802b6"
      },
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtP8p-an_cVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f08b474-802b-40a3-cf87-6d7326b6d72a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAUtr_LVzRIZ"
      },
      "source": [
        "train = pd.read_csv('drive/MyDrive/train_quotes.csv')\n",
        "test = pd.read_csv('drive/MyDrive/test_quotes.csv')"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2SfB07O_bn3"
      },
      "source": [
        "train = train.drop(columns = ['Unnamed: 0', 'Unnamed: 0.1'])\n",
        "test = test.drop(columns = ['Unnamed: 0', 'Unnamed: 0.1'])"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP_rETWH8Nw3"
      },
      "source": [
        "train['top25pct'] = (train['Likes'] >= 89).astype(int)\n",
        "test['top25pct'] = (test['Likes'] >= 89).astype(int)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "eFd9Rmb5A1pe",
        "outputId": "4c83bf40-bc44-4e65-c5db-72f996e1b7c7"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quote</th>\n",
              "      <th>Likes</th>\n",
              "      <th>top25pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>She turned to look at him, and he was already ...</td>\n",
              "      <td>210</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Being in a religion is important but you must ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Shortcuts will only satisfy and give you succe...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Though the earth contains greater energy and m...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A novel is a mirror walking along a main road.</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Quote  Likes  top25pct\n",
              "0  She turned to look at him, and he was already ...    210         1\n",
              "1  Being in a religion is important but you must ...      0         0\n",
              "2  Shortcuts will only satisfy and give you succe...      0         0\n",
              "3  Though the earth contains greater energy and m...      5         0\n",
              "4     A novel is a mirror walking along a main road.    130         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "yiMkSO8dBwSS",
        "outputId": "c83106ce-7a2e-490b-8c3c-fe6e4202333f"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quote</th>\n",
              "      <th>Likes</th>\n",
              "      <th>top25pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beyond work and love, I would add two other in...</td>\n",
              "      <td>350</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A conflict is the harmful expression of differ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Experience is more important than knowledge.</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wake up, for life is only a fleeting moment, b...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It is astounding how it's harder to find a per...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Quote  Likes  top25pct\n",
              "0  Beyond work and love, I would add two other in...    350         1\n",
              "1  A conflict is the harmful expression of differ...      0         0\n",
              "2       Experience is more important than knowledge.     50         0\n",
              "3  Wake up, for life is only a fleeting moment, b...      0         0\n",
              "4  It is astounding how it's harder to find a per...      0         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPBvAUnOCpR5"
      },
      "source": [
        "def upsample_minority(df):\n",
        "\n",
        "  # Upsample minority class in both the training and test data\n",
        "  df_majority = df.loc[df['top25pct'] == 0, :]\n",
        "  df_minority = df.loc[df['top25pct'] == 1, :]\n",
        "  df_minority_upsampled = resample(df_minority, replace = True, n_samples = len(df_majority), random_state = 42)\n",
        "\n",
        "  # Combine together to get the upsampled training data\n",
        "  df = pd.concat([df_majority, df_minority_upsampled])\n",
        "\n",
        "  return df"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYHbXoDRCtdR"
      },
      "source": [
        "# Upsample the minority class\n",
        "train = upsample_minority(train)\n",
        "test = upsample_minority(test)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "IMk9921pDBIE",
        "outputId": "4c9d0c6c-efba-4ea2-b4ac-116a1d2c133e"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quote</th>\n",
              "      <th>Likes</th>\n",
              "      <th>top25pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Being in a religion is important but you must ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Shortcuts will only satisfy and give you succe...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Though the earth contains greater energy and m...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>She wore far too much rouge last night and not...</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Happy Youth Day1 Timothy 4:12Ecclesiastes 12:1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Quote  Likes  top25pct\n",
              "1  Being in a religion is important but you must ...      0         0\n",
              "2  Shortcuts will only satisfy and give you succe...      0         0\n",
              "3  Though the earth contains greater energy and m...      5         0\n",
              "5  She wore far too much rouge last night and not...     26         0\n",
              "7     Happy Youth Day1 Timothy 4:12Ecclesiastes 12:1      0         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "M1fV7-C-DNyK",
        "outputId": "03a85095-4241-46dc-fc48-038202f51b76"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quote</th>\n",
              "      <th>Likes</th>\n",
              "      <th>top25pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A conflict is the harmful expression of differ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Experience is more important than knowledge.</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wake up, for life is only a fleeting moment, b...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It is astounding how it's harder to find a per...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>But then again, that's what the Book of Job wa...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Quote  Likes  top25pct\n",
              "1  A conflict is the harmful expression of differ...      0         0\n",
              "2       Experience is more important than knowledge.     50         0\n",
              "3  Wake up, for life is only a fleeting moment, b...      0         0\n",
              "4  It is astounding how it's harder to find a per...      0         0\n",
              "5  But then again, that's what the Book of Job wa...      3         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EosYfiZByW7"
      },
      "source": [
        "# Preprocessing - to remove length-1 words, and remove non-alphabet symbols\n",
        "def preprocessing(quotes):\n",
        "\n",
        "    processed_quotes = []\n",
        "    \n",
        "    for quote in tqdm(quotes):\n",
        "        \n",
        "        # remove other non-alphabets symbols with space (i.e. keep only alphabets and whitespaces).\n",
        "        processed = re.sub('[^a-zA-Z ]', '', quote)\n",
        "        \n",
        "        words = processed.split()\n",
        "        \n",
        "        # keep words that have length of more than 1 (e.g. gb, bb), remove those with length 1.\n",
        "        processed_quotes.append(' '.join([word for word in words if len(word) > 1]))\n",
        "    \n",
        "    return processed_quotes"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJHOW7VsCISA",
        "outputId": "3cad63e2-a9fd-4daf-aa8e-f7eaad57e710"
      },
      "source": [
        "train['Quote'] = preprocessing(train['Quote'])\n",
        "test['Quote'] = preprocessing(test['Quote'])"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 84710/84710 [00:01<00:00, 74265.79it/s]\n",
            "100%|██████████| 21246/21246 [00:00<00:00, 75542.10it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-z5C98nCjR4"
      },
      "source": [
        "def preprocessing_2(quotes):\n",
        "    \n",
        "    processed_quotes = []\n",
        "\n",
        "    for quote in tqdm(quotes):\n",
        "        tokens = word_tokenize(quote)\n",
        "\n",
        "        # Convert to lower case\n",
        "        tokens = [w.lower() for w in tokens]\n",
        "\n",
        "        # Remove punctuation\n",
        "        table = str.maketrans('', '', string.punctuation)\n",
        "        stripped = [w.translate(table) for w in tokens]\n",
        "\n",
        "        # Remove remaining tokens that are not alphabetic\n",
        "        words = [word for word in stripped if word.isalpha()]\n",
        "        \n",
        "        # Filter out stopwords\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        words = [w for w in words if not w in stop_words]\n",
        "        \n",
        "        processed_quotes.append(words)\n",
        "        \n",
        "    return processed_quotes"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GyNjMkcDYHY",
        "outputId": "f58b751f-d66c-4dbf-d1a8-40f7485634d0"
      },
      "source": [
        "train['Quote'] = preprocessing_2(train['Quote'])\n",
        "test['Quote'] = preprocessing_2(test['Quote'])"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 84710/84710 [00:42<00:00, 2013.12it/s]\n",
            "100%|██████████| 21246/21246 [00:10<00:00, 2033.65it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGAxjktkD53b"
      },
      "source": [
        "# Shuffle test again, and reset index (very important!!!)\n",
        "test = test.sample(frac = 1)\n",
        "test = test.reset_index(drop = True)\n",
        "train = train.reset_index(drop = True)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRTEWa1_EsQJ"
      },
      "source": [
        "# Fitting Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjwuEUqgBg13"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYD0udbnEXan"
      },
      "source": [
        "# Extract the embeddings from the stored file\n",
        "# Embedding is size 111k (# words) x 100 (dimensions)\n",
        "import os \n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join('drive/MyDrive/word2vec_train.txt'), encoding = 'utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:])\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juapCaSeEuGc"
      },
      "source": [
        "def vectorize_text(content):\n",
        "\n",
        "  # Vectorize the text samples into 2D integer tensor - max length 16 words\n",
        "  tokenizer_obj = Tokenizer()\n",
        "\n",
        "  # Fit the tokenizer on the text\n",
        "  tokenizer_obj.fit_on_texts(content)\n",
        "\n",
        "  # Generate the sequence of tokens\n",
        "  sequences = tokenizer_obj.texts_to_sequences(content)\n",
        "\n",
        "  # Get the max length of each article - 5587\n",
        "  max_length = max([len(s) for s in content])\n",
        "  \n",
        "  # Pad the sequences\n",
        "  vectorized_text = pad_sequences(sequences, maxlen = max_length)\n",
        "\n",
        "  return vectorized_text, tokenizer_obj, max_length"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXZcR5Lc_noU"
      },
      "source": [
        "def get_embedding_matrix(tokenizer_obj, EMBEDDING_DIM = 100):\n",
        " \n",
        "  word_index = tokenizer_obj.word_index\n",
        "\n",
        "  num_words = len(word_index) + 1\n",
        "  words_not_found = []\n",
        "  \n",
        "  # Create the emedding matrix - map embeddings from word2vec model for each word and create matrix of word vectors\n",
        "  embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "\n",
        "  for word, i in word_index.items():\n",
        "      if i > num_words: # Least common words (don't care)\n",
        "          continue\n",
        "          \n",
        "      embedding_vector = embeddings_index.get(word)\n",
        "      \n",
        "      if (embedding_vector is not None):\n",
        "          # Assign the ith elmenet of the embedding matrix to the embedding of that word\n",
        "          embedding_matrix[i] = embedding_vector\n",
        "      else:\n",
        "          words_not_found.append(word)\n",
        "          \n",
        "  print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
        "\n",
        "  return embedding_matrix"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-gnE8v1AMwS",
        "outputId": "79156645-1b63-48b0-c4dc-1a4af8db356c"
      },
      "source": [
        "# Vectorize the text (return document x length matrix)\n",
        "train_vectorized, tokenizer, max_length = vectorize_text(train['Quote'])\n",
        "\n",
        "test_vectorized = tokenizer.texts_to_sequences(test['Quote'])\n",
        "test_vectorized = pad_sequences(test_vectorized, maxlen = max_length)\n",
        "\n",
        "# Get the embedding matrix of the words\n",
        "embedding_matrix = get_embedding_matrix(tokenizer)\n",
        "num_words = embedding_matrix.shape[0]"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of null word embeddings: 5586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTwBENmDBxto"
      },
      "source": [
        "# Tuning Deep Learning Model\n",
        "\n",
        "Reference: https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o0wrDLeBFFZ"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Embedding, LSTM, GRU, SpatialDropout1D, Bidirectional, Dropout, BatchNormalization\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.initializers import Constant\n",
        "from keras.optimizers import SGD, Adam\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtrWAGyeogVF",
        "outputId": "8dcf31ac-1169-41ec-bbca-45a91eee834b"
      },
      "source": [
        "# Establish X and y data\n",
        "X_train = train_vectorized\n",
        "X_test = test_vectorized\n",
        "\n",
        "y_train = train['top25pct'].to_numpy()\n",
        "y_test = test['top25pct'].to_numpy()\n",
        "\n",
        "print('Shape of X_train: ', X_train.shape)\n",
        "print('Shape of y_train: ', y_train.shape)\n",
        "print('Shape of X_test: ', X_test.shape)\n",
        "print('Shape of y_test: ', y_test.shape)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_train:  (84710, 373)\n",
            "Shape of y_train:  (84710,)\n",
            "Shape of X_test:  (21246, 373)\n",
            "Shape of y_test:  (21246,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5Whcic_pACx"
      },
      "source": [
        "# Untuned RNN model\n",
        "def RNN_Model(learning_rate, dropout):\n",
        "    \n",
        "    text_sequence = Input(shape = (max_length,), name = 'text_sequence_input')\n",
        "    rnn_layer = Embedding(num_words, EMBEDDING_DIM, weights = [embedding_matrix], trainable = False, name = 'embedding')(text_sequence)\n",
        "    rnn_layer = LSTM(units = 32, dropout = dropout)(rnn_layer)\n",
        "    rnn_layer = Dense(32, activation = 'relu')(rnn_layer)\n",
        "    output = Dense(1, name = 'output')(rnn_layer)\n",
        "    model = Model(inputs = text_sequence, outputs = output)\n",
        "    model.compile(loss = keras.losses.BinaryCrossentropy(from_logits = True), optimizer = Adam(learning_rate = learning_rate), metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpoNg-ihJkv7"
      },
      "source": [
        "# create model\n",
        "model = KerasClassifier(build_fn=RNN_Model, epochs=15, batch_size=32, verbose=1)\n",
        "\n",
        "# define the grid search parameters\n",
        "learning_rate = [0.005, 0.015]\n",
        "dropout = [0.2, 0.5]\n",
        "param_grid = dict(learning_rate=learning_rate, dropout=dropout)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYyN62QRpFcf"
      },
      "source": [
        "# LEARNING_RATE = [0.005, 0.015]\n",
        "# DROPOUT = [0.2, 0.5]\n",
        "# for learning_rate in LEARNING_RATE:\n",
        "#     for dropout in DROPOUT:\n",
        "#         model = RNN_Model(learning_rate, dropout)\n",
        "#         model.summary()\n",
        "#         print(\"learning rate: \" + str(learning_rate))\n",
        "#         print(\"dropout: \" + str(dropout))\n",
        "#         print(\"-----------------------------------------------------------------\")\n",
        "#         history = model.fit(X_train, y_train, batch_size = 32, epochs = 20, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLDi88i9AMhg"
      },
      "source": [
        "# Training Deep Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r4Po87FCMKn"
      },
      "source": [
        "# Tuned RNN model\n",
        "def RNN_Model():\n",
        "    \n",
        "    text_sequence = Input(shape = (max_length,), name = 'text_sequence_input')\n",
        "    rnn_layer = Embedding(num_words, EMBEDDING_DIM, weights = [embedding_matrix], trainable = False, name = 'embedding')(text_sequence)\n",
        "    rnn_layer = LSTM(units = 32, dropout = 0.2)(rnn_layer)\n",
        "    rnn_layer = Dense(32, activation = 'relu')(rnn_layer)\n",
        "    output = Dense(1, name = 'output')(rnn_layer)\n",
        "    model = Model(inputs = text_sequence, outputs = output)\n",
        "    model.compile(loss = keras.losses.BinaryCrossentropy(from_logits = True), optimizer = Adam(learning_rate = 0.005), metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVhq1zXFh0l9",
        "outputId": "53857a3f-d6e5-46e6-ed50-85fad4b1521c"
      },
      "source": [
        "model = RNN_Model()\n",
        "model.summary()\n",
        "history = model.fit(X_train, y_train, batch_size = 32, epochs = 20, verbose = 1)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_sequence_input (InputLa [(None, 373)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 373, 100)          8911900   \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 8,930,013\n",
            "Trainable params: 18,113\n",
            "Non-trainable params: 8,911,900\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2648/2648 [==============================] - 154s 57ms/step - loss: 0.6700 - accuracy: 0.5398\n",
            "Epoch 2/20\n",
            "2648/2648 [==============================] - 153s 58ms/step - loss: 0.6553 - accuracy: 0.5683\n",
            "Epoch 3/20\n",
            "2648/2648 [==============================] - 153s 58ms/step - loss: 0.6561 - accuracy: 0.5705\n",
            "Epoch 4/20\n",
            "2648/2648 [==============================] - 153s 58ms/step - loss: 0.6554 - accuracy: 0.5688\n",
            "Epoch 5/20\n",
            "2648/2648 [==============================] - 154s 58ms/step - loss: 0.6522 - accuracy: 0.5713\n",
            "Epoch 6/20\n",
            "2648/2648 [==============================] - 153s 58ms/step - loss: 0.6495 - accuracy: 0.5764\n",
            "Epoch 7/20\n",
            "2648/2648 [==============================] - 154s 58ms/step - loss: 0.6481 - accuracy: 0.5801\n",
            "Epoch 8/20\n",
            "2648/2648 [==============================] - 154s 58ms/step - loss: 0.6444 - accuracy: 0.5883\n",
            "Epoch 9/20\n",
            "2648/2648 [==============================] - 154s 58ms/step - loss: 0.6447 - accuracy: 0.5836\n",
            "Epoch 10/20\n",
            "2648/2648 [==============================] - 154s 58ms/step - loss: 0.6402 - accuracy: 0.5948\n",
            "Epoch 11/20\n",
            "2648/2648 [==============================] - 153s 58ms/step - loss: 0.6378 - accuracy: 0.5965\n",
            "Epoch 12/20\n",
            "2648/2648 [==============================] - 153s 58ms/step - loss: 0.6348 - accuracy: 0.5971\n",
            "Epoch 13/20\n",
            "2648/2648 [==============================] - 155s 58ms/step - loss: 0.6316 - accuracy: 0.6000\n",
            "Epoch 14/20\n",
            "2648/2648 [==============================] - 155s 59ms/step - loss: 0.6333 - accuracy: 0.5968\n",
            "Epoch 15/20\n",
            "2648/2648 [==============================] - 151s 57ms/step - loss: 0.6321 - accuracy: 0.6003\n",
            "Epoch 16/20\n",
            "2648/2648 [==============================] - 153s 58ms/step - loss: 0.6306 - accuracy: 0.6025\n",
            "Epoch 17/20\n",
            "2648/2648 [==============================] - 154s 58ms/step - loss: 0.6274 - accuracy: 0.6088\n",
            "Epoch 18/20\n",
            "2648/2648 [==============================] - 155s 59ms/step - loss: 0.6287 - accuracy: 0.6030\n",
            "Epoch 19/20\n",
            "2648/2648 [==============================] - 154s 58ms/step - loss: 0.6285 - accuracy: 0.6031\n",
            "Epoch 20/20\n",
            "2648/2648 [==============================] - 153s 58ms/step - loss: 0.6268 - accuracy: 0.6080\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq_xkrb8IErq"
      },
      "source": [
        "# Evaluating Model Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK9EZbN1b4CY"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ_h9n7dzUSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c14934a-f54e-439f-d27d-683120d20646"
      },
      "source": [
        "# Evaluate on test set\n",
        "results = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "664/664 [==============================] - 16s 24ms/step - loss: 0.6585 - accuracy: 0.5945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq9Cag_yGx2J"
      },
      "source": [
        "y_test_probs = model.predict(X_test)\n",
        "y_test_preds = (y_test_probs > 0.5).astype(int)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQwPIC3mHDE9"
      },
      "source": [
        "def get_classification_metrics(actual, pred):\n",
        "  print(confusion_matrix(actual, pred))\n",
        "  print('Accuracy: {}, Precision: {}, Recall: {}, F1 Score: {}'.format(\n",
        "      accuracy_score(actual, pred),\n",
        "      precision_score(actual, pred),\n",
        "      recall_score(actual, pred),\n",
        "      f1_score(actual, pred)))"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqb7AsW8HIVW",
        "outputId": "88e1b868-b709-45d2-8434-0a48186b4973"
      },
      "source": [
        "get_classification_metrics(y_test, y_test_preds)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8670 1953]\n",
            " [6663 3960]]\n",
            "Accuracy: 0.5944648404405535, Precision: 0.669710806697108, Recall: 0.3727760519627224, F1 Score: 0.47895500725689405\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}