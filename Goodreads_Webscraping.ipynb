{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping first half of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n"
     ]
    }
   ],
   "source": [
    "#Initialize quotes list and prepare to scrape first page\n",
    "quotes = []\n",
    "authors = []\n",
    "likes = []\n",
    "\n",
    "#list of tags, and so indirectly, list of web pages to be scraped. This is only half the full list; it was broken up\n",
    "# to make troubleshooting easier\n",
    "tag_list = ['love', 'life', 'inspirational', 'humor', 'philosophy', 'god', 'inspirational-quotes', 'truth', \n",
    "            'wisdom', 'poetry', 'romance', 'death', 'happiness', 'hope', 'faith', 'inspiration', 'quotes']\n",
    "\n",
    "# for every tag, 100 pages of quotes are provided by goodreads.com. Here we scrape data from all of them.\n",
    "for i in tag_list:\n",
    "    for j in range(100):\n",
    "        url = \"https://www.goodreads.com/quotes/tag/{}?page={}\".format(i, j+1)\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        \n",
    "        # this boolean list will be used to handle errors that arise when webscraping\n",
    "        success = [True for k in range(len(soup.find_all(class_=\"quoteText\")))]\n",
    "        \n",
    "        #initialize a count\n",
    "        count_1 = -1\n",
    "        \n",
    "        #for every quote found, add it to the list of quotes\n",
    "        for my_tag in soup.find_all(class_=\"quoteText\"):\n",
    "            count_1 += 1\n",
    "            try:\n",
    "                # Occasionally, an issue would arise with scraping author data. If this happens, none of the data \n",
    "                # associated with that quote should be added to the dataset. To accomplish this, in the event of \n",
    "                # an error, appending the author data fails, appending the quotes data is skipped, and the success \n",
    "                # boolean at the current index is set to false.\n",
    "                authors.append(my_tag.text.split(\"//\")[0].split(\"窶表")[1].split(\",\")[0])\n",
    "                quotes.append(my_tag.text.split(\"//\")[0].split(\"窶表")[0])\n",
    "            except:\n",
    "                success[count_1] = False\n",
    "                continue\n",
    "        \n",
    "        #initialize a count that will mirror the values of the first count as the following loop is executed.\n",
    "        count_2 = -1\n",
    "        \n",
    "        # The likes data is scraped from different html code, so it is scraped in a separate for loop. A count is \n",
    "        # in place to ensure that certain rows are skipped when the corresponding data was not successfully scraped.\n",
    "        for my_tag in soup.find_all('a', {'class': 'smallText', 'title': 'View this quote'}):\n",
    "            count_2 += 1\n",
    "            # if the corresponding author and quote data was successfully scraped\n",
    "            if success[count_2] == True:\n",
    "                likes.append(my_tag.text.split(\" \")[0])\n",
    "        \n",
    "        #way to monitor progress\n",
    "        if (j+1) % 100 == 0:    \n",
    "            print('tag done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50995\n",
      "50995\n",
      "50995\n"
     ]
    }
   ],
   "source": [
    "#these should all be the same magnitude\n",
    "print(len(quotes))\n",
    "print(len(authors))\n",
    "print(len(likes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of extra white spaces\n",
    "quotes = [quote.strip() for quote in quotes]\n",
    "authors = [author.strip() for author in authors]\n",
    "likes = [like.strip() for like in likes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of parentheses around quotes\n",
    "quotes = [quote[1:] for quote in quotes]\n",
    "quotes = [quote[:-1] for quote in quotes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping second half of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this section is analogous to the code in the first section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n",
      "tag done\n"
     ]
    }
   ],
   "source": [
    "quotes_2 = []\n",
    "authors_2 = []\n",
    "likes_2 = []\n",
    "\n",
    "tag_list_2 = ['writing', 'religion', 'life-lessons', 'motivational', 'success', 'relationships', 'spirituality', \n",
    "            'time', 'love-quotes', 'knowledge', 'life-quotes', 'science', 'books']\n",
    "\n",
    "for i in tag_list_2:\n",
    "    for j in range(100):\n",
    "        url = \"https://www.goodreads.com/quotes/tag/{}?page={}\".format(i, j+1)\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "        success = [True for k in range(len(soup.find_all(class_=\"quoteText\")))]\n",
    "        \n",
    "        count_1 = -1\n",
    "        #for every quote found, add it to the list of quotes\n",
    "        for my_tag in soup.find_all(class_=\"quoteText\"):\n",
    "            count_1 += 1\n",
    "            try:\n",
    "                authors_2.append(my_tag.text.split(\"//\")[0].split(\"窶表")[1].split(\",\")[0])\n",
    "                quotes_2.append(my_tag.text.split(\"//\")[0].split(\"窶表")[0])\n",
    "            except:\n",
    "                success[count_1] = False\n",
    "                continue\n",
    "        \n",
    "        count_2 = -1\n",
    "        for my_tag in soup.find_all('a', {'class': 'smallText', 'title': 'View this quote'}):\n",
    "            count_2 += 1\n",
    "            if success[count_2] == True:\n",
    "                    likes_2.append(my_tag.text.split(\" \")[0])\n",
    "\n",
    "        if (j+1) % 100 == 0:    \n",
    "            print('tag done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_spare_2 = quotes_2\n",
    "authors_spare_2 = authors_2\n",
    "likes_spare_2 = likes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2 = [quote_2.strip() for quote_2 in quotes_2]\n",
    "authors_2 = [author_2.strip() for author_2 in authors_2]\n",
    "likes_2 = [like_2.strip() for like_2 in likes_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2 = [quote_2[1:] for quote_2 in quotes_2]\n",
    "quotes_2 = [quote_2[:-1] for quote_2 in quotes_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining the data and creating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining data\n",
    "Quotes = quotes + quotes_2\n",
    "Authors = authors + authors_2\n",
    "Likes = likes + likes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe with quotes\n",
    "df = pd.DataFrame(Quotes,columns=['Quote'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Author'] = Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Likes'] = Likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89995, 3)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['Quote'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70773, 3)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('quote_data.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm selfish, impatient and a little insecure. ...</td>\n",
       "      <td>153436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You've gotta dance like there's nobody watchin...</td>\n",
       "      <td>120542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You know you're in love when you can't fall as...</td>\n",
       "      <td>117305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A friend is someone who knows all about you an...</td>\n",
       "      <td>79638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Darkness cannot drive out darkness: only light...</td>\n",
       "      <td>73740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Quote   Likes\n",
       "0  I'm selfish, impatient and a little insecure. ...  153436\n",
       "1  You've gotta dance like there's nobody watchin...  120542\n",
       "2  You know you're in love when you can't fall as...  117305\n",
       "3  A friend is someone who knows all about you an...   79638\n",
       "4  Darkness cannot drive out darkness: only light...   73740"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('quote_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
