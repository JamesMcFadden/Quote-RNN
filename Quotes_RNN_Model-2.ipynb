{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quotes_RNN_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Pn0FG81KBZeP",
        "tRTEWa1_EsQJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn0FG81KBZeP"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT-JIlC0yrRb",
        "outputId": "5836279c-8d30-4875-d9b0-f519b75ac974"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auKEQQwsy6xX"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import resample\n",
        "\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-2bXLjgzCND",
        "outputId": "e2faf59e-e936-4681-fd30-7a98785fe6bd"
      },
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtP8p-an_cVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "790acb87-8737-4952-e9f0-20a34d58c3b1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAUtr_LVzRIZ"
      },
      "source": [
        "train = pd.read_csv('drive/MyDrive/train_quotes.csv')\n",
        "test = pd.read_csv('drive/MyDrive/test_quotes.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2SfB07O_bn3"
      },
      "source": [
        "train = train.drop(columns = ['Unnamed: 0', 'Unnamed: 0.1'])\n",
        "test = test.drop(columns = ['Unnamed: 0', 'Unnamed: 0.1'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP_rETWH8Nw3"
      },
      "source": [
        "train['top25pct'] = (train['Likes'] >= 89).astype(int)\n",
        "test['top25pct'] = (test['Likes'] >= 89).astype(int)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "eFd9Rmb5A1pe",
        "outputId": "25879868-029f-4bec-e818-1da2f5defbad"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quote</th>\n",
              "      <th>Author</th>\n",
              "      <th>Likes</th>\n",
              "      <th>top25pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Politics is a fair and good enough profession ...</td>\n",
              "      <td>Nurudeen Ushawu</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is the legend of Cassius Clay, The most b...</td>\n",
              "      <td>Muhammad Ali</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The cosmos is within us. We are made of star-s...</td>\n",
              "      <td>Carl Sagan</td>\n",
              "      <td>927</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A poet is, before anything else, a person who ...</td>\n",
              "      <td>W.H. Auden</td>\n",
              "      <td>550</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>When I have a little money, I buy books; and i...</td>\n",
              "      <td>Desiderius Erasmus Roterodamus</td>\n",
              "      <td>8459</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Quote  ... top25pct\n",
              "0  Politics is a fair and good enough profession ...  ...        0\n",
              "1  This is the legend of Cassius Clay, The most b...  ...        0\n",
              "2  The cosmos is within us. We are made of star-s...  ...        1\n",
              "3  A poet is, before anything else, a person who ...  ...        1\n",
              "4  When I have a little money, I buy books; and i...  ...        1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "yiMkSO8dBwSS",
        "outputId": "da9ef4fd-5d3e-4a47-b8a5-273ad216e012"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quote</th>\n",
              "      <th>Author</th>\n",
              "      <th>Likes</th>\n",
              "      <th>top25pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You might asked why I loved you.For the same r...</td>\n",
              "      <td>Tatjana Ostojic</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>..time is always the price we pay for the unli...</td>\n",
              "      <td>André Aciman</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As above so below,can I, with you, go? Alwayst...</td>\n",
              "      <td>Lavinia Valeriana</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The ocean pulsed outside our window. The sound...</td>\n",
              "      <td>Chelsie Shakespeare</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Penyakit yang Menghambat Dunia Islam :Pertama,...</td>\n",
              "      <td>Habiburrahman El Shirazy</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Quote  ... top25pct\n",
              "0  You might asked why I loved you.For the same r...  ...        0\n",
              "1  ..time is always the price we pay for the unli...  ...        0\n",
              "2  As above so below,can I, with you, go? Alwayst...  ...        0\n",
              "3  The ocean pulsed outside our window. The sound...  ...        0\n",
              "4  Penyakit yang Menghambat Dunia Islam :Pertama,...  ...        0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPBvAUnOCpR5"
      },
      "source": [
        "def upsample_minority(df):\n",
        "\n",
        "  # Upsample minority class in both the training and test data\n",
        "  df_majority = df.loc[df['top25pct'] == 0, :]\n",
        "  df_minority = df.loc[df['top25pct'] == 1, :]\n",
        "  df_minority_upsampled = resample(df_minority, replace = True, n_samples = len(df_majority), random_state = 42)\n",
        "\n",
        "  # Combine together to get the upsampled training data\n",
        "  df = pd.concat([df_majority, df_minority_upsampled])\n",
        "\n",
        "  return df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYHbXoDRCtdR"
      },
      "source": [
        "# Upsample the minority class\n",
        "train = upsample_minority(train)\n",
        "test = upsample_minority(test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "IMk9921pDBIE",
        "outputId": "9e5844c2-bd0d-4168-d137-dd1f916b16c6"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quote</th>\n",
              "      <th>Author</th>\n",
              "      <th>Likes</th>\n",
              "      <th>top25pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Politics is a fair and good enough profession ...</td>\n",
              "      <td>Nurudeen Ushawu</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is the legend of Cassius Clay, The most b...</td>\n",
              "      <td>Muhammad Ali</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The Second Koran tells us that the darkness in...</td>\n",
              "      <td>Maureen F. McHugh</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>A powerful woman can stand, even after a fall....</td>\n",
              "      <td>Gift Gugu Mona</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Aye. And I can do without a viper-tongued wenc...</td>\n",
              "      <td>Jennifer La Brecque</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Quote  ... top25pct\n",
              "0  Politics is a fair and good enough profession ...  ...        0\n",
              "1  This is the legend of Cassius Clay, The most b...  ...        0\n",
              "5  The Second Koran tells us that the darkness in...  ...        0\n",
              "6  A powerful woman can stand, even after a fall....  ...        0\n",
              "7  Aye. And I can do without a viper-tongued wenc...  ...        0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "M1fV7-C-DNyK",
        "outputId": "92514e8b-138c-4e06-802f-023cad6c1563"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quote</th>\n",
              "      <th>Author</th>\n",
              "      <th>Likes</th>\n",
              "      <th>top25pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You might asked why I loved you.For the same r...</td>\n",
              "      <td>Tatjana Ostojic</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>..time is always the price we pay for the unli...</td>\n",
              "      <td>André Aciman</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As above so below,can I, with you, go? Alwayst...</td>\n",
              "      <td>Lavinia Valeriana</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The ocean pulsed outside our window. The sound...</td>\n",
              "      <td>Chelsie Shakespeare</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Penyakit yang Menghambat Dunia Islam :Pertama,...</td>\n",
              "      <td>Habiburrahman El Shirazy</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Quote  ... top25pct\n",
              "0  You might asked why I loved you.For the same r...  ...        0\n",
              "1  ..time is always the price we pay for the unli...  ...        0\n",
              "2  As above so below,can I, with you, go? Alwayst...  ...        0\n",
              "3  The ocean pulsed outside our window. The sound...  ...        0\n",
              "4  Penyakit yang Menghambat Dunia Islam :Pertama,...  ...        0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EosYfiZByW7"
      },
      "source": [
        "# Preprocessing - to remove length-1 words, and remove non-alphabet symbols\n",
        "def preprocessing(quotes):\n",
        "\n",
        "    processed_quotes = []\n",
        "    \n",
        "    for quote in tqdm(quotes):\n",
        "        \n",
        "        # remove other non-alphabets symbols with space (i.e. keep only alphabets and whitespaces).\n",
        "        processed = re.sub('[^a-zA-Z ]', '', quote)\n",
        "        \n",
        "        words = processed.split()\n",
        "        \n",
        "        # keep words that have length of more than 1 (e.g. gb, bb), remove those with length 1.\n",
        "        processed_quotes.append(' '.join([word for word in words if len(word) > 1]))\n",
        "    \n",
        "    return processed_quotes"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJHOW7VsCISA",
        "outputId": "3ac5b7e3-efbe-4e5c-da96-75383d07ca89"
      },
      "source": [
        "train['Quote'] = preprocessing(train['Quote'])\n",
        "test['Quote'] = preprocessing(test['Quote'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 85242/85242 [00:01<00:00, 73815.23it/s]\n",
            "100%|██████████| 21298/21298 [00:00<00:00, 79359.98it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-z5C98nCjR4"
      },
      "source": [
        "def preprocessing_2(quotes):\n",
        "    \n",
        "    processed_quotes = []\n",
        "\n",
        "    for quote in tqdm(quotes):\n",
        "        tokens = word_tokenize(quote)\n",
        "\n",
        "        # Convert to lower case\n",
        "        tokens = [w.lower() for w in tokens]\n",
        "\n",
        "        # Remove punctuation\n",
        "        table = str.maketrans('', '', string.punctuation)\n",
        "        stripped = [w.translate(table) for w in tokens]\n",
        "\n",
        "        # Remove remaining tokens that are not alphabetic\n",
        "        words = [word for word in stripped if word.isalpha()]\n",
        "        \n",
        "        # Filter out stopwords\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        words = [w for w in words if not w in stop_words]\n",
        "        \n",
        "        processed_quotes.append(words)\n",
        "        \n",
        "    return processed_quotes"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GyNjMkcDYHY",
        "outputId": "edfd2604-09d6-48c9-d98c-f0e59a73930e"
      },
      "source": [
        "train['Quote'] = preprocessing_2(train['Quote'])\n",
        "test['Quote'] = preprocessing_2(test['Quote'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 85242/85242 [00:37<00:00, 2289.27it/s]\n",
            "100%|██████████| 21298/21298 [00:09<00:00, 2264.30it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGAxjktkD53b"
      },
      "source": [
        "# Shuffle test again, and reset index (very important!!!)\n",
        "test = test.sample(frac = 1)\n",
        "test = test.reset_index(drop = True)\n",
        "train = train.reset_index(drop = True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRTEWa1_EsQJ"
      },
      "source": [
        "# Fitting Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjwuEUqgBg13"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYD0udbnEXan"
      },
      "source": [
        "# Extract the embeddings from the stored file\n",
        "# Embedding is size 111k (# words) x 100 (dimensions)\n",
        "import os \n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join('drive/MyDrive/word2vec_train.txt'), encoding = 'utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:])\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juapCaSeEuGc"
      },
      "source": [
        "def vectorize_text(content):\n",
        "\n",
        "  # Vectorize the text samples into 2D integer tensor - max length 16 words\n",
        "  tokenizer_obj = Tokenizer()\n",
        "\n",
        "  # Fit the tokenizer on the text\n",
        "  tokenizer_obj.fit_on_texts(content)\n",
        "\n",
        "  # Generate the sequence of tokens\n",
        "  sequences = tokenizer_obj.texts_to_sequences(content)\n",
        "\n",
        "  # Get the max length of each quote\n",
        "  max_length = max([len(s) for s in content])\n",
        "  \n",
        "  # Pad the sequences\n",
        "  vectorized_text = pad_sequences(sequences, maxlen = max_length)\n",
        "\n",
        "  return vectorized_text, tokenizer_obj, max_length"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXZcR5Lc_noU"
      },
      "source": [
        "def get_embedding_matrix(tokenizer_obj, EMBEDDING_DIM = 100):\n",
        " \n",
        "  word_index = tokenizer_obj.word_index\n",
        "\n",
        "  num_words = len(word_index) + 1\n",
        "  words_not_found = []\n",
        "  \n",
        "  # Create the emedding matrix - map embeddings from word2vec model for each word and create matrix of word vectors\n",
        "  embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "\n",
        "  for word, i in word_index.items():\n",
        "      if i > num_words: # Least common words (don't care)\n",
        "          continue\n",
        "          \n",
        "      embedding_vector = embeddings_index.get(word)\n",
        "      \n",
        "      if (embedding_vector is not None):\n",
        "          # Assign the ith elmenet of the embedding matrix to the embedding of that word\n",
        "          embedding_matrix[i] = embedding_vector\n",
        "      else:\n",
        "          words_not_found.append(word)\n",
        "          \n",
        "  print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
        "\n",
        "  return embedding_matrix"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-gnE8v1AMwS",
        "outputId": "e9e72cd8-10d5-400b-dcb2-50cd374c5056"
      },
      "source": [
        "# Vectorize the text (return document x length matrix)\n",
        "train_vectorized, tokenizer, max_length = vectorize_text(train['Quote'])\n",
        "\n",
        "test_vectorized = tokenizer.texts_to_sequences(test['Quote'])\n",
        "test_vectorized = pad_sequences(test_vectorized, maxlen = max_length)\n",
        "\n",
        "# Get the embedding matrix of the words\n",
        "embedding_matrix = get_embedding_matrix(tokenizer)\n",
        "num_words = embedding_matrix.shape[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of null word embeddings: 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTwBENmDBxto"
      },
      "source": [
        "# Tuning Deep Learning Model\n",
        "\n",
        "Reference: https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
        "\n",
        "https://towardsdatascience.com/combining-numerical-and-text-features-in-deep-neural-networks-e91f0237eea4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1QVdiGZTts_",
        "outputId": "4893d4a5-2b50-40ff-f2fe-23e1a2f1961d"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 26.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 21.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o0wrDLeBFFZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55dfe01c-2a3d-4724-e3b3-275a2d001e28"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Concatenate, Input, Dense, Embedding, LSTM, GRU, SpatialDropout1D, Bidirectional, Dropout, BatchNormalization, concatenate\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.initializers import Constant\n",
        "from keras.optimizers import SGD, Adam\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtrWAGyeogVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd075f1b-8fff-4108-c5d3-108c9ed0627e"
      },
      "source": [
        "# Establish X and y data\n",
        "X_train = train_vectorized\n",
        "X_test = test_vectorized\n",
        "\n",
        "encoder = TargetEncoder()\n",
        "X_train_authors = encoder.fit_transform(train['Author'], train['Likes'])\n",
        "X_test_authors = encoder.fit_transform(test['Author'], test['Likes'])\n",
        "\n",
        "y_train = train['top25pct'].to_numpy()\n",
        "y_test = test['top25pct'].to_numpy()\n",
        "\n",
        "print('Shape of X_train: ', X_train.shape)\n",
        "print('Shape of y_train: ', y_train.shape)\n",
        "print('Shape of X_test: ', X_test.shape)\n",
        "print('Shape of y_test: ', y_test.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_train:  (85242, 367)\n",
            "Shape of y_train:  (85242,)\n",
            "Shape of X_test:  (21298, 367)\n",
            "Shape of y_test:  (21298,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n",
            "/usr/local/lib/python3.6/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5Whcic_pACx"
      },
      "source": [
        "# Untuned RNN model\n",
        "# def RNN_Model(learning_rate, dropout):\n",
        "    \n",
        "#     text_sequence = Input(shape = (max_length,), name = 'text_sequence_input')\n",
        "#     meta_input = Input(shape=(1,))\n",
        "#     rnn_layer = Embedding(num_words, EMBEDDING_DIM, weights = [embedding_matrix], trainable = False, name = 'embedding')(text_sequence)\n",
        "#     rnn_layer = LSTM(units = 32, dropout = dropout)(rnn_layer)\n",
        "#     concat = concatenate([rnn_layer, meta_input])\n",
        "#     rnn_layer = Dense(32, activation = 'relu')(concat)\n",
        "#     output = Dense(1, name = 'output')(rnn_layer)\n",
        "#     model = Model(inputs = [text_sequence, meta_input], outputs = output)\n",
        "#     model.compile(loss = keras.losses.BinaryCrossentropy(from_logits = True), optimizer = Adam(learning_rate = learning_rate), metrics = ['accuracy'])\n",
        "    \n",
        "#     return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpoNg-ihJkv7"
      },
      "source": [
        "# # create model\n",
        "# model = KerasClassifier(build_fn=RNN_Model, epochs=15, batch_size=32, verbose=1)\n",
        "\n",
        "# # define the grid search parameters\n",
        "# learning_rate = [0.005, 0.015]\n",
        "# dropout = [0.2, 0.5]\n",
        "# param_grid = dict(learning_rate=learning_rate, dropout=dropout)\n",
        "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
        "# grid_result = grid.fit([X_train, X_train_authors], y_train)\n",
        "\n",
        "# # summarize results\n",
        "# print(\"Best score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYyN62QRpFcf"
      },
      "source": [
        "# LEARNING_RATE = [0.005, 0.015]\n",
        "# DROPOUT = [0.2, 0.5]\n",
        "# for learning_rate in LEARNING_RATE:\n",
        "#     for dropout in DROPOUT:\n",
        "#         model = RNN_Model(learning_rate, dropout)\n",
        "#         model.summary()\n",
        "#         print(\"learning rate: \" + str(learning_rate))\n",
        "#         print(\"dropout: \" + str(dropout))\n",
        "#         print(\"-----------------------------------------------------------------\")\n",
        "#         history = model.fit(X_train, y_train, batch_size = 32, epochs = 20, verbose = 1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLDi88i9AMhg"
      },
      "source": [
        "# Training Deep Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r4Po87FCMKn"
      },
      "source": [
        "# Tuned RNN model\n",
        "def RNN_Model():\n",
        "    \n",
        "    text_sequence = Input(shape = (max_length,), name = 'text_sequence_input')\n",
        "    meta_input = Input(shape=(1,))\n",
        "    rnn_layer = Embedding(num_words, EMBEDDING_DIM, weights = [embedding_matrix], trainable = True, name = 'embedding')(text_sequence)\n",
        "    rnn_layer = LSTM(units = 32, dropout = 0.6)(rnn_layer)\n",
        "    concat = concatenate([rnn_layer, meta_input])\n",
        "    rnn_layer = Dense(32, activation = 'tanh')(concat)\n",
        "    output = Dense(1, name = 'output')(rnn_layer)\n",
        "    model = Model(inputs = [text_sequence, meta_input], outputs = output)\n",
        "    model.compile(loss = keras.losses.BinaryCrossentropy(from_logits = True), optimizer = Adam(learning_rate = 0.0005), metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVhq1zXFh0l9",
        "outputId": "2b349042-7ce6-458c-beba-c6065b31f4ce"
      },
      "source": [
        "model = RNN_Model()\n",
        "model.summary()\n",
        "history = model.fit([X_train, X_train_authors], y_train, batch_size = 32, epochs = 12, verbose = 1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text_sequence_input (InputLayer [(None, 367)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 367, 100)     8852800     text_sequence_input[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 32)           17024       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 33)           0           lstm_3[0][0]                     \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           1088        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            33          dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,870,945\n",
            "Trainable params: 8,870,945\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/12\n",
            "2664/2664 [==============================] - 277s 103ms/step - loss: 0.5471 - accuracy: 0.6649\n",
            "Epoch 2/12\n",
            "2664/2664 [==============================] - 275s 103ms/step - loss: 0.5045 - accuracy: 0.7269\n",
            "Epoch 3/12\n",
            "2664/2664 [==============================] - 276s 104ms/step - loss: 0.3628 - accuracy: 0.8323\n",
            "Epoch 4/12\n",
            "2664/2664 [==============================] - 275s 103ms/step - loss: 0.2555 - accuracy: 0.8842\n",
            "Epoch 5/12\n",
            "2664/2664 [==============================] - 275s 103ms/step - loss: 0.2129 - accuracy: 0.9068\n",
            "Epoch 6/12\n",
            "2664/2664 [==============================] - 274s 103ms/step - loss: 0.1883 - accuracy: 0.9193\n",
            "Epoch 7/12\n",
            "2664/2664 [==============================] - 274s 103ms/step - loss: 0.1715 - accuracy: 0.9279\n",
            "Epoch 8/12\n",
            "2664/2664 [==============================] - 275s 103ms/step - loss: 0.1566 - accuracy: 0.9343\n",
            "Epoch 9/12\n",
            "2664/2664 [==============================] - 275s 103ms/step - loss: 0.1459 - accuracy: 0.9390\n",
            "Epoch 10/12\n",
            "2664/2664 [==============================] - 275s 103ms/step - loss: 0.1415 - accuracy: 0.9423\n",
            "Epoch 11/12\n",
            "2664/2664 [==============================] - 275s 103ms/step - loss: 0.1290 - accuracy: 0.9479\n",
            "Epoch 12/12\n",
            "2664/2664 [==============================] - 276s 103ms/step - loss: 0.1269 - accuracy: 0.9499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq_xkrb8IErq"
      },
      "source": [
        "# Evaluating Model Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK9EZbN1b4CY"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ_h9n7dzUSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "409a8713-0373-4653-95d7-db26c15aae4e"
      },
      "source": [
        "# Evaluate on test set\n",
        "results = model.evaluate([X_test, X_test_authors], y_test)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "666/666 [==============================] - 6s 8ms/step - loss: 1.3378 - accuracy: 0.6526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq9Cag_yGx2J"
      },
      "source": [
        "y_test_probs = model.predict([X_test, X_test_authors])\n",
        "y_test_preds = (y_test_probs > 0.5).astype(int)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQwPIC3mHDE9"
      },
      "source": [
        "def get_classification_metrics(actual, pred):\n",
        "  print(confusion_matrix(actual, pred))\n",
        "  print('Accuracy: {}, Precision: {}, Recall: {}, F1 Score: {}'.format(\n",
        "      accuracy_score(actual, pred),\n",
        "      precision_score(actual, pred),\n",
        "      recall_score(actual, pred),\n",
        "      f1_score(actual, pred)))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqb7AsW8HIVW",
        "outputId": "e57bf353-69b8-491a-99d7-482bb3ccd3f3"
      },
      "source": [
        "get_classification_metrics(y_test, y_test_preds)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8830 1819]\n",
            " [5580 5069]]\n",
            "Accuracy: 0.6525964879331393, Precision: 0.735917537746806, Recall: 0.4760071368203587, F1 Score: 0.5780920339852882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzcopifhpSUY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}